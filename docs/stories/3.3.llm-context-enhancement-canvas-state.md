# Story 3.3: LLM Context Enhancement with Canvas State

**Status:** In Progress

**Epic:** Epic 3: Interactive Whiteboard Collaboration

---

## Story

**As a** tutor (LLM),
**I want** to receive the canvas visual state along with conversation history,
**so that** I can see what the student has drawn and adapt my guidance accordingly.

---

## Acceptance Criteria

1. API route (`/api/chat`) enhanced to accept canvas image along with text message ✓ (already implemented)
2. Canvas image sent to GPT-4 Vision API as part of the conversation context
3. System prompt updated to instruct tutor:
   - "You can see the student's work on the whiteboard. Blue markings are the student's drawings."
   - "Reference what you see them doing visually when asking guiding questions."
   - "If they've drawn something incorrect, ask questions about their visual approach."
4. Test validation: Tutor responds to student's visual work appropriately
5. Canvas state included in API calls only when student has drawn something (optimization: don't send if canvas is unchanged)
6. Error handling: If Vision API fails, fall back to text-only conversation (graceful degradation)

---

## Dev Notes

### Architecture Context

**Existing Implementation:**
- `/api/chat` route already accepts `canvasSnapshot` parameter ✓
- `llmService.processMessage()` already accepts `canvasSnapshot` but currently ignores it
- GPT-4 Vision API already used for image parsing (parseImage method)

**Required Changes:**
1. Update `processMessage()` to use GPT-4 Vision when canvas snapshot provided
2. Add canvas context instructions to system prompt
3. Implement graceful degradation if Vision API fails

### Technical Implementation

**GPT-4 Vision Integration:**
- Use `gpt-4-vision-preview` model when canvas snapshot provided
- Format current message as multi-part content: text + image
- System prompt remains as text-only message
- Conversation history remains text-only (previous messages don't need vision)

**System Prompt Enhancement:**
Add canvas awareness section:
```
CANVAS VISUAL CONTEXT:
- You can see the student's work on the whiteboard through the attached image.
- Blue markings/lines are the student's drawings and work.
- Orange markings (if present) are previous tutor annotations.
- Reference what you see them doing visually when asking guiding questions.
- If they've drawn something incorrect, ask questions about their visual approach.
- Example: "I see you've drawn a number line. Can you explain what the marks represent?"
```

**Error Handling:**
- Try-catch around Vision API call
- If vision fails, log error and fall back to text-only model
- Ensure graceful degradation (conversation continues without visual context)

---

## Tasks / Subtasks

- [x] Update System Prompt with Canvas Context (AC: 3)
  - [x] Add CANVAS VISUAL CONTEXT section to SOCRATIC_TUTOR_SYSTEM_PROMPT_V1
  - [x] Include instructions about blue (student) markings
  - [x] Include instructions about referencing visual work in questions
  - [x] Add example of visual-aware tutoring

- [x] Implement Vision API Integration in processMessage (AC: 2, 5)
  - [x] Check if canvasSnapshot is provided and non-empty
  - [x] Use gpt-4-vision-preview model when snapshot present
  - [x] Format current message as multi-part content (text + image)
  - [x] Keep conversation history as text-only
  - [x] Only send vision if student has drawn (empty canvas optimization)

- [x] Implement Error Handling and Fallback (AC: 6)
  - [x] Wrap Vision API call in try-catch
  - [x] Log vision failures for debugging
  - [x] Fall back to text-only gpt-4-turbo if vision fails
  - [x] Ensure conversation continues without visual context

- [x] Build and Compile Check
  - [x] Run npm run build to verify TypeScript compilation
  - [x] Fix any type errors or compilation issues

- [ ] Integration Testing (AC: 4)
  - [x] Code compiles successfully
  - [ ] Manual test: Send message with canvas snapshot (requires browser)
  - [ ] Verify tutor references visual work in response
  - [ ] Test fallback behavior (simulated vision API failure)

---

## Agent Model Used

claude-sonnet-4-5-20250929 (Orchestrator coordinating development workflow)

---

## Dev Agent Record

### Debug Log References

None yet

### Completion Notes

- **2025-11-04:** Implemented Vision API integration for canvas context
  - Updated SOCRATIC_TUTOR_SYSTEM_PROMPT_V1 with CANVAS VISUAL CONTEXT section
  - Modified processMessage() to use gpt-4-vision-preview when canvas snapshot provided
  - Implemented smart detection: only use vision if snapshot > 100 bytes and valid data URI
  - Added graceful fallback: Vision API failures automatically retry with text-only gpt-4-turbo
  - Canvas snapshot sent as multi-part content (text + image) in current message
  - Conversation history remains text-only (no vision needed for past messages)
  - Error handling with console logging for debugging
  - Code compiles successfully (npm run build ✓)
  - Manual browser testing pending for end-to-end validation

### File List

**Source Files Created:**
- (none - modifying existing files)

**Source Files Modified:**
- `src/services/prompts.ts` (added CANVAS VISUAL CONTEXT section to system prompt)
- `src/services/llmService.ts` (integrated GPT-4 Vision API in processMessage with fallback)

**Source Files Deleted:**
- (none)

**Test Files Created:**
- (none - manual testing sufficient for MVP)

**Test Files Modified:**
- (none)

**Other Files Modified:**
- (none)

---

## Change Log

| Date | Author | Change Description |
|------|--------|-------------------|
| 2025-11-04 | Orchestrator | Story created from PRD Epic 3.3 requirements |
| 2025-11-04 | Orchestrator | Implemented Vision API integration: updated system prompt, added vision/fallback logic in processMessage |

---
